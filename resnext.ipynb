{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "WINDOW_SIZE = 42\n",
    "RANDOM_SEED = 42 # NEVER CHANGE THIS\n",
    "NUM_FOLDS = 5\n",
    "import numpy as np\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectData(Dataset):\n",
    "    def __init__(self,folder,files,window_size,sensors):\n",
    "        self.sensors = sensors\n",
    "        self.window_size = window_size\n",
    "        self.files = files\n",
    "        self.num_trials = len(self.files)\n",
    "        self.num_slices = self.num_trials * [-1]\n",
    "        self.trial_start_idx = self.num_trials * [-1]\n",
    "        self.tables = self.num_trials * [None]\n",
    "        for i,file in enumerate(self.files):\n",
    "            num_lines = sum(1 for line in open(folder+file))\n",
    "            num_samples = num_lines-1\n",
    "            self.num_slices[i] = num_samples-window_size+1\n",
    "            self.tables[i] = pd.read_csv(folder+file)\n",
    "            if i == 0:\n",
    "                self.trial_start_idx[i] = 0\n",
    "            else:\n",
    "                self.trial_start_idx[i] = self.trial_start_idx[i-1] + self.num_slices[i-1]\n",
    "        self.len = sum(self.num_slices)\n",
    "\n",
    "    def get_slice(self, trial_idx, slice):\n",
    "        skiprows = lambda i: i != 0 and i < slice[0]\n",
    "        nrows = slice[1]-slice[0]\n",
    "        action = torch.tensor(self.tables[trial_idx].Action.values[slice[1]-1])\n",
    "        contact = torch.tensor(self.tables[trial_idx].ContactMode.values[slice[1]-1])\n",
    "        phase = torch.tensor(self.tables[trial_idx].Phase.values[slice[1]-1])\n",
    "        sensors = torch.tensor(self.tables[trial_idx][self.sensors].values[slice[0]:slice[1],:])\n",
    "        return sensors.T,action,contact,phase\n",
    "    \n",
    "    def find_trial_from_idx(self, idx): # a binary search algorithm\n",
    "        a,b = 0,self.num_trials\n",
    "        m = (a+b)//2\n",
    "        while True:\n",
    "            y = self.trial_start_idx[m]\n",
    "            if y == idx:\n",
    "                return m\n",
    "            elif y > idx:\n",
    "                b = m\n",
    "            elif y < idx:\n",
    "                a = m\n",
    "            if (b-a) <= 1:\n",
    "                return a\n",
    "            m = (a+b)//2\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        if idx >= self.len:\n",
    "            raise IndexError()\n",
    "        trial = self.find_trial_from_idx(idx)\n",
    "        slice = (idx - self.trial_start_idx[trial], idx - self.trial_start_idx[trial] + self.window_size)\n",
    "        return self.get_slice(trial, slice)\n",
    "\n",
    "SENSORS = [\"foot_Accel_X\",\n",
    "           \"foot_Accel_Y\", \n",
    "           \"foot_Accel_Z\",\n",
    "           \"foot_Gyro_X\",\n",
    "           \"foot_Gyro_Y\",\n",
    "           \"foot_Gyro_Z\",\n",
    "           \"shank_Accel_X\",\n",
    "           \"shank_Accel_Y\",\n",
    "           \"shank_Accel_Z\",\n",
    "           \"shank_Gyro_X\",\n",
    "           \"shank_Gyro_Y\",\n",
    "           \"shank_Gyro_Z\",\n",
    "           \"thigh_Accel_X\",\n",
    "           \"thigh_Accel_Y\",\n",
    "           \"thigh_Accel_Z\",\n",
    "           \"thigh_Gyro_X\",\n",
    "           \"thigh_Gyro_Y\",\n",
    "           \"thigh_Gyro_Z\",\n",
    "           \"trunk_Accel_X\",\n",
    "           \"trunk_Accel_Y\",\n",
    "           \"trunk_Accel_Z\",\n",
    "           \"trunk_Gyro_X\",\n",
    "           \"trunk_Gyro_Y\",\n",
    "           \"trunk_Gyro_Z\",\n",
    "           \"gastrocmed\",\n",
    "           \"vastusmedialis\",\n",
    "           \"vastuslateralis\",\n",
    "           \"tibialisanterior\",\n",
    "           \"rectusfemoris\",\n",
    "           \"bicepsfemoris\",\n",
    "]\n",
    "\n",
    "IMU = [ \"foot_Accel_X\",\n",
    "        \"foot_Accel_Y\", \n",
    "        \"foot_Accel_Z\",\n",
    "        \"foot_Gyro_X\",\n",
    "        \"foot_Gyro_Y\",\n",
    "        \"foot_Gyro_Z\",\n",
    "        \"shank_Accel_X\",\n",
    "        \"shank_Accel_Y\",\n",
    "        \"shank_Accel_Z\",\n",
    "        \"shank_Gyro_X\",\n",
    "        \"shank_Gyro_Y\",\n",
    "        \"shank_Gyro_Z\",\n",
    "        \"thigh_Accel_X\",\n",
    "        \"thigh_Accel_Y\",\n",
    "        \"thigh_Accel_Z\",\n",
    "        \"thigh_Gyro_X\",\n",
    "        \"thigh_Gyro_Y\",\n",
    "        \"thigh_Gyro_Z\",\n",
    "        \"trunk_Accel_X\",\n",
    "        \"trunk_Accel_Y\",\n",
    "        \"trunk_Accel_Z\",\n",
    "        \"trunk_Gyro_X\",\n",
    "        \"trunk_Gyro_Y\",\n",
    "        \"trunk_Gyro_Z\"\n",
    "]\n",
    "\n",
    "EMG = [\n",
    "        \"gastrocmed\",\n",
    "        \"vastusmedialis\",\n",
    "        \"vastuslateralis\",\n",
    "        \"tibialisanterior\",\n",
    "        \"rectusfemoris\",\n",
    "        \"bicepsfemoris\",\n",
    "]\n",
    "\n",
    "def make_folds(K,folder,files,window_size,sensors):\n",
    "    _files = np.array(files)\n",
    "    N = len(files)\n",
    "    M = N//K\n",
    "    indices = np.random.choice(N,N,replace=False)\n",
    "    folds = K*[None]\n",
    "    for i in range(K-1):\n",
    "        folds[i] = _files[indices[i*M:(i+1)*M]]\n",
    "    folds[K-1] = _files[indices[(K-1)*M:-1]]\n",
    "    return [ProjectData(folder,folds[i],window_size,sensors) for i in range(K)]\n",
    "\n",
    "\n",
    "training_files = os.listdir(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXtBlock(nn.Module):\n",
    "    def __init__(self, num_sensors, window_size, kernels, dilation):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(\n",
    "                num_sensors,num_sensors,\n",
    "                kernels[0],\n",
    "                padding='same',\n",
    "                dilation=dilation[0],\n",
    "                groups=num_sensors)\n",
    "        self.bn1 = nn.LazyBatchNorm1d()\n",
    "        self.conv2 = nn.Conv1d(\n",
    "                num_sensors,num_sensors,\n",
    "                kernels[1],\n",
    "                padding='same',\n",
    "                dilation=dilation[1],\n",
    "                groups=num_sensors)\n",
    "        self.bn2 = nn.LazyBatchNorm1d()\n",
    "        self.conv3 = nn.Conv1d(\n",
    "                num_sensors,num_sensors,\n",
    "                kernels[2],\n",
    "                padding='same',\n",
    "                dilation=dilation[2])\n",
    "        self.bn3 = nn.LazyBatchNorm1d()\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = nn.functional.relu(self.bn1(self.conv1(X)))\n",
    "        Y = nn.functional.relu(self.bn2(self.conv2(X)))\n",
    "        Y = self.bn3(self.conv3(Y))\n",
    "        return nn.functional.relu(Y+X)\n",
    "    \n",
    "class ResNeXt(nn.Module):\n",
    "    def __init__(self, num_sensors, window_size, kernels, dilation, num_blocks):\n",
    "        super().__init__()\n",
    "        self.loss_weights=torch.tensor([1,1,1])\n",
    "        blocks = [ResNeXtBlock(num_sensors,window_size,kernels,dilation) for i in range(num_blocks)] \n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.bn = nn.LazyBatchNorm1d()\n",
    "        self.gap = nn.AdaptiveAvgPool1d(5)\n",
    "        self.fc1 = nn.LazyLinear(5)\n",
    "        self.fc2 = nn.LazyLinear(2)\n",
    "        self.fc3 = nn.LazyLinear(2)\n",
    "    \n",
    "    def forward(self, sensors):\n",
    "        # return self.blocks[0](sensors)\n",
    "        Y = torch.flatten(self.gap(self.bn(self.blocks(sensors))),start_dim=1,end_dim=-1)\n",
    "        action_logits = self.fc1(Y)\n",
    "        contact_logits = self.fc2(Y)\n",
    "        phase_xy = self.fc3(Y)\n",
    "        phase = torch.atan2(phase_xy[:,0],phase_xy[:,1])\n",
    "        return action_logits, contact_logits, phase + torch.pi\n",
    "\n",
    "    def loss(self, action_logits, contact_logits, phase_pred, action, contact, phase):\n",
    "        loss = self.loss_weights[0]*nn.functional.cross_entropy(action_logits, action)\n",
    "        loss += self.loss_weights[1]*nn.functional.cross_entropy(contact_logits, contact)\n",
    "        # convert phases to cartesian_coords\n",
    "        xy = torch.vstack((torch.cos(phase),torch.sin(phase)))\n",
    "        xy_pred = torch.vstack((torch.cos(phase_pred),torch.sin(phase_pred)))\n",
    "        loss += self.loss_weights[2]*nn.functional.mse_loss(xy_pred,xy)\n",
    "        return loss\n",
    "\n",
    "    def to(self,device):\n",
    "        super().to(device)\n",
    "        self.loss_weights = self.loss_weights.to(device)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgs/miniconda3/envs/directml/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# testing model constructor\n",
    "model = ResNeXt(\n",
    "    len(SENSORS),\n",
    "    WINDOW_SIZE,\n",
    "    [3,3,3],\n",
    "    [1,2,3],\n",
    "    10\n",
    ")\n",
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains model on dataloader.dataset\n",
    "def train_loop(dataloader, model, device, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    epoch_loss = 0\n",
    "    for batch, (sensors,action,contact,phase) in enumerate(dataloader):\n",
    "        sensors = sensors.to(device)\n",
    "        action = action.to(device)\n",
    "        contact = contact.to(device)\n",
    "        phase = phase.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        action_logits, contact_logits, phase_pred = model(sensors)\n",
    "        loss = model.loss(action_logits, contact_logits, phase_pred, action, contact, phase)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(sensors)\n",
    "            # print(f\"average loss: {loss/len(batch):>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return epoch_loss\n",
    "\n",
    "# tests model on dataloader.dataset\n",
    "def test_loop(dataloader, model, device):\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, (sensors,action,contact,phase) in enumerate(dataloader):\n",
    "            sensors = sensors.to(device)\n",
    "            action = action.to(device)\n",
    "            contact = contact.to(device)\n",
    "            phase = phase.to(device)\n",
    "            # Compute prediction and loss\n",
    "            action_logits, contact_logits, phase_pred = model(sensors)\n",
    "            epoch_loss += model.loss(action_logits, contact_logits, phase_pred, action, contact, phase).item()\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs k-fold cross-validation training for two essential hyper-parameters:\n",
    "# 1) Window size (how many past measurements are used for inference)\n",
    "# 2) Sensors (which signals are used for inference)\n",
    "# Note that these hyperparameters change both the dataset and the network width\n",
    "def kfold_training(K,window_size,sensors,epochs,dataframe):\n",
    "    sensor_sets = {\"EMG\" : EMG, \"IMU\": IMU, \"EMG+IMU\": SENSORS}\n",
    "    folds = make_folds(K,\"train/\",training_files,window_size,sensor_sets[sensors])\n",
    "    K = len(folds)\n",
    "    loss = K*[None]\n",
    "    for i in range(K):\n",
    "        model = ResNeXt(\n",
    "            len(sensor_sets[sensors]),\n",
    "            window_size,\n",
    "            [3,3,3],\n",
    "            [1,2,3],\n",
    "            10\n",
    "        )\n",
    "        model = model.double()\n",
    "        model = model.to(\"cuda\")\n",
    "        optimizer = torch.optim.SGD(model.parameters(),1e-3,momentum=0.9,nesterov=True)\n",
    "        for t in range(epochs):\n",
    "            train_loss = 0\n",
    "            for j in range(K):\n",
    "                if j == i:\n",
    "                    continue\n",
    "                dataloader = DataLoader(folds[j],batch_size=4096,shuffle=True,num_workers=8)\n",
    "                train_loss += train_loop(dataloader,model,\"cuda\",optimizer)\n",
    "            dataloader = DataLoader(folds[i],batch_size=4096,num_workers=8)\n",
    "            validation_loss = test_loop(dataloader, model, \"cuda\")\n",
    "            df = pd.DataFrame({\n",
    "                \"Window Size\": window_size,\n",
    "                \"Sensors\": sensors,\n",
    "                \"Fold\": i,\n",
    "                \"Epoch\": t,\n",
    "                \"Train Loss\": [train_loss],\n",
    "                \"Validation Loss\": [validation_loss]\n",
    "            })\n",
    "            dataframe = pd.concat((dataframe,df))\n",
    "            print(dataframe)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgs/miniconda3/envs/directml/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Window Size Sensors Fold Epoch   Train Loss  Validation Loss\n",
      "0          10     EMG    0     0  1000.478677       233.516736\n",
      "  Window Size Sensors Fold Epoch   Train Loss  Validation Loss\n",
      "0          10     EMG    0     0  1000.478677       233.516736\n",
      "0          10     EMG    0     1   902.974508       226.947823\n",
      "  Window Size Sensors Fold Epoch   Train Loss  Validation Loss\n",
      "0          10     EMG    0     0  1000.478677       233.516736\n",
      "0          10     EMG    0     1   902.974508       226.947823\n",
      "0          10     EMG    0     2   882.501823       223.639982\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m window_size \u001b[39min\u001b[39;00m window_sizes:\n\u001b[1;32m      7\u001b[0m     \u001b[39mfor\u001b[39;00m sensors \u001b[39min\u001b[39;00m sensor_sets:\n\u001b[0;32m----> 8\u001b[0m         df \u001b[39m=\u001b[39m kfold_training(\u001b[39m5\u001b[39;49m,window_size,sensors,epochs,df)\n",
      "Cell \u001b[0;32mIn[6], line 29\u001b[0m, in \u001b[0;36mkfold_training\u001b[0;34m(K, window_size, sensors, epochs, dataframe)\u001b[0m\n\u001b[1;32m     27\u001b[0m     train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m train_loop(dataloader,model,\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m,optimizer)\n\u001b[1;32m     28\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(folds[i],batch_size\u001b[39m=\u001b[39m\u001b[39m4096\u001b[39m,num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m validation_loss \u001b[39m=\u001b[39m test_loop(dataloader, model, \u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     30\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m     31\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mWindow Size\u001b[39m\u001b[39m\"\u001b[39m: window_size,\n\u001b[1;32m     32\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mSensors\u001b[39m\u001b[39m\"\u001b[39m: sensors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mValidation Loss\u001b[39m\u001b[39m\"\u001b[39m: [validation_loss]\n\u001b[1;32m     37\u001b[0m })\n\u001b[1;32m     38\u001b[0m dataframe \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat((dataframe,df))\n",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m, in \u001b[0;36mtest_loop\u001b[0;34m(dataloader, model, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m epoch_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mfor\u001b[39;00m batch, (sensors,action,contact,phase) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     31\u001b[0m         sensors \u001b[39m=\u001b[39m sensors\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m         action \u001b[39m=\u001b[39m action\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/directml/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/directml/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/directml/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1283\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/directml/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/directml/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/directml/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/directml/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/directml/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/directml/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run 5-fold cross-validation over 9 sets of hyper parameters\n",
    "# window_sizes = [10,25,75]\n",
    "# sensor_sets = [\"EMG\",\"IMU\",\"EMG+IMU\"]\n",
    "# epochs = 5\n",
    "# df = pd.DataFrame(columns = [\"Window Size\", \"Sensors\", \"Fold\", \"Epoch\", \"Train Loss\", \"Validation Loss\"])\n",
    "# for window_size in window_sizes:\n",
    "#     for sensors in sensor_sets:\n",
    "#         df = kfold_training(5,window_size,sensors,epochs,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the results into a dataframe\n",
    "\n",
    "# import seaborn as sns\n",
    "# import seaborn.objects as so\n",
    "# from matplotlib import pyplot as plt\n",
    "# ax = sns.swarmplot(dataframe,x=\"Sensors\",y=\"Loss\",hue=\"window size\",palette=\"tab10\")\n",
    "# ax.set_title(\"Five-Fold Cross-Validation Loss of Models\")\n",
    "# plt.savefig(\"resnext10 crossval study.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgs/miniconda3/envs/directml/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgs/miniconda3/envs/directml/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n",
      "0          70     IMU    1     0  680.387996        81.789701\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n",
      "0          70     IMU    1     0  680.387996        81.789701\n",
      "0          70     IMU    1     1  336.268502        58.041528\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n",
      "0          70     IMU    1     0  680.387996        81.789701\n",
      "0          70     IMU    1     1  336.268502        58.041528\n",
      "0          70     IMU    1     2  217.721403        50.870223\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n",
      "0          70     IMU    1     0  680.387996        81.789701\n",
      "0          70     IMU    1     1  336.268502        58.041528\n",
      "0          70     IMU    1     2  217.721403        50.870223\n",
      "0          70     IMU    1     3  171.567056        49.115019\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n",
      "0          70     IMU    1     0  680.387996        81.789701\n",
      "0          70     IMU    1     1  336.268502        58.041528\n",
      "0          70     IMU    1     2  217.721403        50.870223\n",
      "0          70     IMU    1     3  171.567056        49.115019\n",
      "0          70     IMU    1     4  147.136729        48.577843\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n",
      "0          70     IMU    1     0  680.387996        81.789701\n",
      "0          70     IMU    1     1  336.268502        58.041528\n",
      "0          70     IMU    1     2  217.721403        50.870223\n",
      "0          70     IMU    1     3  171.567056        49.115019\n",
      "0          70     IMU    1     4  147.136729        48.577843\n",
      "0          70     IMU    1     5  131.361790        48.870502\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n",
      "0          70     IMU    1     0  680.387996        81.789701\n",
      "0          70     IMU    1     1  336.268502        58.041528\n",
      "0          70     IMU    1     2  217.721403        50.870223\n",
      "0          70     IMU    1     3  171.567056        49.115019\n",
      "0          70     IMU    1     4  147.136729        48.577843\n",
      "0          70     IMU    1     5  131.361790        48.870502\n",
      "0          70     IMU    1     6  120.952335        49.024069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jgs/miniconda3/envs/directml/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n",
      "0          70     IMU    1     0  680.387996        81.789701\n",
      "0          70     IMU    1     1  336.268502        58.041528\n",
      "0          70     IMU    1     2  217.721403        50.870223\n",
      "0          70     IMU    1     3  171.567056        49.115019\n",
      "0          70     IMU    1     4  147.136729        48.577843\n",
      "0          70     IMU    1     5  131.361790        48.870502\n",
      "0          70     IMU    1     6  120.952335        49.024069\n",
      "0          70     IMU    2     0  657.505088        89.189420\n",
      "  Window Size Sensors Fold Epoch  Train Loss  Validation Loss\n",
      "0          70     IMU    0     0  658.158829        74.142022\n",
      "0          70     IMU    0     1  302.313886        56.625108\n",
      "0          70     IMU    0     2  204.521188        53.057677\n",
      "0          70     IMU    0     3  164.870926        52.261207\n",
      "0          70     IMU    0     4  143.671930        52.111264\n",
      "0          70     IMU    0     5  130.556079        52.527088\n",
      "0          70     IMU    0     6  121.121041        53.322133\n",
      "0          70     IMU    1     0  680.387996        81.789701\n",
      "0          70     IMU    1     1  336.268502        58.041528\n",
      "0          70     IMU    1     2  217.721403        50.870223\n",
      "0          70     IMU    1     3  171.567056        49.115019\n",
      "0          70     IMU    1     4  147.136729        48.577843\n",
      "0          70     IMU    1     5  131.361790        48.870502\n",
      "0          70     IMU    1     6  120.952335        49.024069\n",
      "0          70     IMU    2     0  657.505088        89.189420\n",
      "0          70     IMU    2     1  316.082255        67.008117\n"
     ]
    }
   ],
   "source": [
    "# Best trade-off is IMU, so we will train the model using IMU data and 70 data samples per sensor\n",
    "# Run 7-fold cross-validation for 7 epochs\n",
    "# takes about 2.5 hours on my desktop computer with a cuda device\n",
    "df = pd.DataFrame(columns = [\"Window Size\", \"Sensors\", \"Fold\", \"Epoch\", \"Train Loss\", \"Validation Loss\"])\n",
    "df = kfold_training(7,70,\"IMU\",7,df)\n",
    "# Overfitting seems to occur after 5 epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "directml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
